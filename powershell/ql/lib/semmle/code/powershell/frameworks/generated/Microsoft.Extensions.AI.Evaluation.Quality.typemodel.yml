# THIS FILE IS AN AUTO-GENERATED MODELS AS DATA FILE. DO NOT EDIT.
extensions:
  - addsTo:
      pack: microsoft/powershell-all
      extensible: typeModel
    data:
    - ["system.string", "microsoft.extensions.ai.evaluation.quality.relevancetruthandcompletenessevaluator!", "Member[truthmetricname]"]
    - ["system.string", "microsoft.extensions.ai.evaluation.quality.relevanceevaluator!", "Member[relevancemetricname]"]
    - ["system.threading.tasks.valuetask", "microsoft.extensions.ai.evaluation.quality.relevanceevaluator", "Method[evaluateasync].ReturnValue"]
    - ["system.collections.generic.ireadonlycollection", "microsoft.extensions.ai.evaluation.quality.relevanceevaluator", "Member[evaluationmetricnames]"]
    - ["system.threading.tasks.valuetask", "microsoft.extensions.ai.evaluation.quality.equivalenceevaluator", "Method[evaluateasync].ReturnValue"]
    - ["system.collections.generic.ireadonlycollection", "microsoft.extensions.ai.evaluation.quality.fluencyevaluator", "Member[evaluationmetricnames]"]
    - ["system.string", "microsoft.extensions.ai.evaluation.quality.groundednessevaluator!", "Member[groundednessmetricname]"]
    - ["system.string", "microsoft.extensions.ai.evaluation.quality.coherenceevaluator!", "Member[coherencemetricname]"]
    - ["system.threading.tasks.valuetask", "microsoft.extensions.ai.evaluation.quality.relevancetruthandcompletenessevaluator", "Method[evaluateasync].ReturnValue"]
    - ["system.threading.tasks.valuetask", "microsoft.extensions.ai.evaluation.quality.coherenceevaluator", "Method[evaluateasync].ReturnValue"]
    - ["system.string", "microsoft.extensions.ai.evaluation.quality.equivalenceevaluatorcontext!", "Member[groundtruthcontextname]"]
    - ["system.string", "microsoft.extensions.ai.evaluation.quality.equivalenceevaluatorcontext", "Member[groundtruth]"]
    - ["system.string", "microsoft.extensions.ai.evaluation.quality.relevancetruthandcompletenessevaluator!", "Member[completenessmetricname]"]
    - ["system.string", "microsoft.extensions.ai.evaluation.quality.equivalenceevaluator!", "Member[equivalencemetricname]"]
    - ["system.threading.tasks.valuetask", "microsoft.extensions.ai.evaluation.quality.completenessevaluator", "Method[evaluateasync].ReturnValue"]
    - ["system.string", "microsoft.extensions.ai.evaluation.quality.retrievalevaluator!", "Member[retrievalmetricname]"]
    - ["system.collections.generic.ireadonlylist", "microsoft.extensions.ai.evaluation.quality.retrievalevaluatorcontext", "Member[retrievedcontextchunks]"]
    - ["system.string", "microsoft.extensions.ai.evaluation.quality.completenessevaluatorcontext", "Member[groundtruth]"]
    - ["system.collections.generic.ireadonlycollection", "microsoft.extensions.ai.evaluation.quality.retrievalevaluator", "Member[evaluationmetricnames]"]
    - ["system.string", "microsoft.extensions.ai.evaluation.quality.relevancetruthandcompletenessevaluator!", "Member[relevancemetricname]"]
    - ["system.collections.generic.ireadonlycollection", "microsoft.extensions.ai.evaluation.quality.completenessevaluator", "Member[evaluationmetricnames]"]
    - ["system.string", "microsoft.extensions.ai.evaluation.quality.groundednessevaluatorcontext!", "Member[groundingcontextname]"]
    - ["system.threading.tasks.valuetask", "microsoft.extensions.ai.evaluation.quality.groundednessevaluator", "Method[evaluateasync].ReturnValue"]
    - ["system.threading.tasks.valuetask", "microsoft.extensions.ai.evaluation.quality.retrievalevaluator", "Method[evaluateasync].ReturnValue"]
    - ["system.string", "microsoft.extensions.ai.evaluation.quality.completenessevaluatorcontext!", "Member[groundtruthcontextname]"]
    - ["system.threading.tasks.valuetask", "microsoft.extensions.ai.evaluation.quality.fluencyevaluator", "Method[evaluateasync].ReturnValue"]
    - ["system.string", "microsoft.extensions.ai.evaluation.quality.groundednessevaluatorcontext", "Member[groundingcontext]"]
    - ["system.string", "microsoft.extensions.ai.evaluation.quality.completenessevaluator!", "Member[completenessmetricname]"]
    - ["system.collections.generic.ireadonlycollection", "microsoft.extensions.ai.evaluation.quality.coherenceevaluator", "Member[evaluationmetricnames]"]
    - ["system.collections.generic.ireadonlycollection", "microsoft.extensions.ai.evaluation.quality.equivalenceevaluator", "Member[evaluationmetricnames]"]
    - ["system.string", "microsoft.extensions.ai.evaluation.quality.retrievalevaluatorcontext!", "Member[retrievedcontextchunkscontextname]"]
    - ["system.string", "microsoft.extensions.ai.evaluation.quality.fluencyevaluator!", "Member[fluencymetricname]"]
    - ["system.collections.generic.ireadonlycollection", "microsoft.extensions.ai.evaluation.quality.relevancetruthandcompletenessevaluator", "Member[evaluationmetricnames]"]
    - ["system.collections.generic.ireadonlycollection", "microsoft.extensions.ai.evaluation.quality.groundednessevaluator", "Member[evaluationmetricnames]"]
